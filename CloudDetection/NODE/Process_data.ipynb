{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab24c0f-84a2-4ef4-af54-cac47071bc58",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Extract and Print Radiance Layer Data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a72d45b-9d8b-431f-80ed-8dc593ee9dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radiance data shape for 162: (1200, 1500, 6)\n",
      "Radiance data shape for 164: (1200, 1500, 6)\n",
      "Radiance data shape for 171: (1200, 1500, 6)\n",
      "Radiance data shape for 181: (1200, 1500, 6)\n",
      "Radiance data shape for 183: (1200, 1500, 6)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Define base path and data directory\n",
    "base_path = 'D:/CloudDetection/'\n",
    "data_dir = os.path.join(base_path, 'images')\n",
    "\n",
    "# Get all subdirectories\n",
    "subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "\n",
    "# Extract Radiance layer data\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    \n",
    "    # Load Radiance dataset\n",
    "    radiance_ds = xr.open_mfdataset(f'{subdir_path}/S*_radiance_in.nc', combine='by_coords')\n",
    "    \n",
    "    # Stack all Radiance layers\n",
    "    radiance_data = []\n",
    "    for var in radiance_ds.data_vars:\n",
    "        radiance_data.append(radiance_ds[var].values)\n",
    "    radiance_data = np.stack(radiance_data, axis=-1)\n",
    "    \n",
    "    # Print Radiance data shape\n",
    "    print(f\"Radiance data shape for {subdir}: {radiance_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ff82d-196e-47a5-98ba-572d5a7eed0f",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Extract and Print BT Layer Data**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b077c7-2ac1-40fb-8dab-95702f811ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT data shape for 162: (1200, 1500, 3)\n",
      "BT data shape for 164: (1200, 1500, 3)\n",
      "BT data shape for 171: (1200, 1500, 3)\n",
      "BT data shape for 181: (1200, 1500, 3)\n",
      "BT data shape for 183: (1200, 1500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Extract BT layer data\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    \n",
    "    # Load BT dataset\n",
    "    bt_ds = xr.open_mfdataset(f'{subdir_path}/S*_BT_in.nc', combine='by_coords')\n",
    "    \n",
    "    # Stack BT layers\n",
    "    bt_data = []\n",
    "    for var in ['S7_BT_in', 'S8_BT_in', 'S9_BT_in']:\n",
    "        data = bt_ds[var].values\n",
    "        bt_data.append(data)\n",
    "    bt_data = np.stack(bt_data, axis=-1)\n",
    "    \n",
    "    # Print BT data shape\n",
    "    print(f\"BT data shape for {subdir}: {bt_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8cdf2-4e85-46f7-abaa-786dadda521f",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Merge Radiance and BT Data and Print Combined Shape**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f2af1f-e09a-4613-91a6-5a3a01ed3ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data shape for 162: (1200, 1500, 9)\n",
      "Combined data shape for 164: (1200, 1500, 9)\n",
      "Combined data shape for 171: (1200, 1500, 9)\n",
      "Combined data shape for 181: (1200, 1500, 9)\n",
      "Combined data shape for 183: (1200, 1500, 9)\n"
     ]
    }
   ],
   "source": [
    "# Merge Radiance and BT data\n",
    "combined_data_dict = {}\n",
    "\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    \n",
    "    # Load Radiance dataset and stack layers\n",
    "    radiance_ds = xr.open_mfdataset(f'{subdir_path}/S*_radiance_in.nc', combine='by_coords')\n",
    "    radiance_data = []\n",
    "    for var in radiance_ds.data_vars:\n",
    "        radiance_data.append(radiance_ds[var].values)\n",
    "    radiance_data = np.stack(radiance_data, axis=-1)\n",
    "    \n",
    "    # Load BT dataset and stack layers\n",
    "    bt_ds = xr.open_mfdataset(f'{subdir_path}/S*_BT_in.nc', combine='by_coords')\n",
    "    bt_data = []\n",
    "    for var in ['S7_BT_in', 'S8_BT_in', 'S9_BT_in']:\n",
    "        data = bt_ds[var].values\n",
    "        bt_data.append(data)\n",
    "    bt_data = np.stack(bt_data, axis=-1)\n",
    "    \n",
    "    # Merge Radiance and BT data into one array\n",
    "    combined_data = np.concatenate([radiance_data, bt_data], axis=-1)\n",
    "    \n",
    "    # Store combined data for later use\n",
    "    combined_data_dict[subdir] = combined_data\n",
    "    \n",
    "    # Print combined data shape\n",
    "    print(f\"Combined data shape for {subdir}: {combined_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a5c40-b937-4c56-9ce1-a74a51d736ea",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Extract and Process Features and Labels**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd48b20-2579-40a1-97e4-b73f3363139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a list to store all rows from all subdirectories\n",
    "all_rows = []\n",
    "\n",
    "# Label encoding: Clear -> 0, Ice -> 1, Cloud -> 2\n",
    "label_encoding = {'Clear': 0, 'Ice': 1, 'Cloud': 2}\n",
    "\n",
    "# Extract and process features and labels for each subdirectory\n",
    "for subdir in subdirs:\n",
    "    subdir_path = os.path.join(data_dir, subdir)\n",
    "    \n",
    "    # Get the combined feature data (Radiance + BT)\n",
    "    combined_data = combined_data_dict[subdir]\n",
    "    \n",
    "    # Load label data (Clear, Ice, Cloud)\n",
    "    clear_labels = xr.open_dataset(os.path.join(subdir_path, 'clear_labels.nc'))['Clear']\n",
    "    ice_labels = xr.open_dataset(os.path.join(subdir_path, 'ice_labels.nc'))['Ice']\n",
    "    cloud_labels = xr.open_dataset(os.path.join(subdir_path, 'cloud_labels.nc'))['Cloud']\n",
    "    \n",
    "    # Create masks for each label\n",
    "    clear_mask = (clear_labels > 0)\n",
    "    ice_mask = (ice_labels > 0)\n",
    "    cloud_mask = (cloud_labels > 0)\n",
    "    \n",
    "    # Process Clear label features\n",
    "    clear_features = combined_data[clear_mask.values]\n",
    "    for feature in clear_features:\n",
    "        all_rows.append([label_encoding['Clear']] + feature.tolist())\n",
    "    \n",
    "    # Process Ice label features\n",
    "    ice_features = combined_data[ice_mask.values]\n",
    "    for feature in ice_features:\n",
    "        all_rows.append([label_encoding['Ice']] + feature.tolist())\n",
    "    \n",
    "    # Process Cloud label features\n",
    "    cloud_features = combined_data[cloud_mask.values]\n",
    "    for feature in cloud_features:\n",
    "        all_rows.append([label_encoding['Cloud']] + feature.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e862bc-9c42-4eb4-a2a8-0e25b5005cff",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Merge Data and Save to CSV**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab989f8-f8a5-4cee-8437-5a753223b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged CSV: 638937 rows, saved to D:/CloudDetection/NODE/data/csv\\merged_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert all rows to a DataFrame\n",
    "df = pd.DataFrame(all_rows, columns=['label'] + [f'feature{i+1}' for i in range(combined_data.shape[-1])])\n",
    "\n",
    "# Sort the DataFrame by the label column\n",
    "df = df.sort_values(by='label')\n",
    "\n",
    "# Define output path for the merged CSV file\n",
    "output_csv_file = os.path.join(base_path, 'NODE/data/csv', 'merged_features.csv')\n",
    "\n",
    "# Ensure the CSV output directory exists\n",
    "os.makedirs(os.path.dirname(output_csv_file), exist_ok=True)\n",
    "\n",
    "# Save the merged data to a single CSV file\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"Saved merged CSV: {df.shape[0]} rows, saved to {output_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479f0824-46c2-46b9-9ce0-133256cebf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "csv_path = r'D:\\CloudDetection\\NODE\\data\\merged_features.csv'\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Split data based on label values\n",
    "class_0 = data[data['label'] == 0]\n",
    "class_1 = data[data['label'] == 1]\n",
    "class_2 = data[data['label'] == 2]\n",
    "\n",
    "# Undersample each class to 70,000 samples\n",
    "class_0_under = class_0.sample(n=70000, random_state=42)\n",
    "class_1_under = class_1.sample(n=70000, random_state=42)\n",
    "class_2_under = class_2.sample(n=70000, random_state=42)\n",
    "\n",
    "# Concatenate the undersampled data\n",
    "balanced_data = pd.concat([class_0_under, class_1_under, class_2_under])\n",
    "\n",
    "# Shuffle the data\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the balanced data to a new CSV file\n",
    "balanced_data.to_csv(r'D:\\CloudDetection\\NODE\\data\\balanced_merged_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea38b3-c578-4ac8-acae-f8be28ce9124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
